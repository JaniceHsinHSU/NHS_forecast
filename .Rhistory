# Convert the YearMonth column to an actual date for processing
data1_full$YearMonth <- ymd(paste0(data1_full$YearMonth, "-01"))
# Create a complete combination of all YearMonths and key_combined
all_dates <- seq.Date(min(data1_full$YearMonth), max(data1_full$YearMonth), by="month")
all_keys <- unique(data1_full$key_combined)
complete_data <- expand.grid(YearMonth = all_dates, key_combined = all_keys)
# Join the complete data with the original data to ensure every combination exists
data_filled <- left_join(complete_data, data1_full, by=c("YearMonth", "key_combined"))
# Fill NAs in the Number column with 0 (or keep as NA depending on context)
data_filled$Number[is.na(data_filled$Number)] <- 0
# Pivot the data wider
data1_wide <- data_filled %>%
filter(year(YearMonth) > 2015) %>%
pivot_wider(names_from = key_combined, values_from = Number)
# Diagnostic Steps
cat("Dimensions of data1_wide:", dim(data1_wide), "\n")
missing_values_matrix <- is.na(data1_wide)
missing_values <- sum(missing_values_matrix)
if (length(missing_values) == 1 && missing_values > 0) {
cat("Number of missing values in data1_wide:", missing_values, "\n")
} else if (length(missing_values) > 1) {
cat("Unexpected result: missing_values isn't a single number. It's a vector or matrix.\n")
}
# Convert to time series
y <- as.matrix(data1_wide[,-1])  # Omitting the YearMonth column
ts_data <- ts(y, start = c(year(min(data_filled$YearMonth)), month(min(data_filled$YearMonth))), frequency = 12)
# Check the dimensions of ts_data
cat("Dimensions of ts_data:", dim(ts_data), "\n")
gts_data <- hts(ts_data)
return(gts_data)
}
# Usage:
# gts_obj = reconcile_data1_wide_paths(data1_full)
# Usage:
gts_obj = reconcile_data1_wide_paths(data1_full)
library(tsibble)
library(tidyr)
library(lubridate)
library(hts)
reconcile_data1_wide_paths <- function(data1_full) {
# Convert YearMonth to date and then filter rows after 2015
data1_wide <- data1_full %>%
filter(year(ymd(paste0(YearMonth, "-01"))) > 2015) %>%
select(-key_combined) %>%
pivot_wider(names_from = c(Grouped_Organisation, Grouped_Age, Hospital_ItemName_ENG), values_from = Number)
# Check for missing values
missing_values_matrix <- is.na(data1_wide)
missing_values <- sum(missing_values_matrix)
# Diagnostic messages
cat("Value of missing_values:", missing_values, "\n")
cat("Length of missing_values:", length(missing_values), "\n")
cat("Is missing_values NA:", is.na(missing_values), "\n")
if (length(missing_values) == 1 && missing_values > 0) {
cat("Number of missing values in data1_wide:", missing_values, "\n")
# Replace missing values if necessary
data1_wide[missing_values_matrix] <- 0
} else if (length(missing_values) > 1) {
cat("Unexpected result: missing_values isn't a single number. It's a vector or matrix.\n")
}
# Convert the data to a gts object
ts_data <- ts(data1_wide[,-1], frequency = 12, start = c(year(min(ymd(paste0(data1_wide$YearMonth, "-01")))), month(min(ymd(paste0(data1_wide$YearMonth, "-01"))))))
gts_obj <- hts(ts_data)
return(gts_obj)
}
# Calling the function
gts_obj = reconcile_data1_wide_paths(data1_full)
library(dplyr)
library(tidyr)
library(lubridate)
library(hts)
reconcile_data1_wide_paths <- function(data1_full) {
# Convert to regular data frame to bypass tsibble constraints
data1_full <- as.data.frame(data1_full)
# Convert YearMonth to date and then filter rows after 2015
data1_wide <- data1_full %>%
filter(year(ymd(paste0(YearMonth, "-01"))) > 2015) %>%
unite("key_column", Grouped_Organisation, Grouped_Age, Hospital_ItemName_ENG, sep = "_") %>%
pivot_wider(names_from = key_column, values_from = Number, values_fill = list(Number = 0))
# Convert the data to a gts object
ts_data <- ts(data1_wide[,-1], frequency = 12, start = c(year(min(ymd(paste0(data1_wide$YearMonth, "-01")))), month(min(ymd(paste0(data1_wide$YearMonth, "-01"))))))
gts_obj <- hts(ts_data)
return(gts_obj)
}
# Calling the function
gts_obj = reconcile_data1_wide_paths(data1_full)
gts_obj
library(stringr)
library(dplyr)
create_ensembles <- function(data1_wide, models_to_use = "all") {
# Extract models/columns from the data1_wide dataframe
models <- colnames(data1_wide)[-1]  # Assuming the first column is 'YearMonth'
models <- models %>%
str_extract("[a-zA-Z]*_") %>%
str_remove("_") %>%
unique()
if (!identical(models_to_use, "all")) {
models <- models[models %in% models_to_use]
if (length(intersect(models, models_to_use)) != length(models_to_use)) {
stop("Some models not available")
}
}
# Create ensemble: For the sake of this example, let's assume ensemble means averaging over the selected models.
# Adjust the function as per the real ensemble requirement.
ensemble <- data1_wide %>%
select(c('YearMonth', all_of(models))) %>%
rowwise() %>%
mutate(ensemble = mean(c_across(everything()), na.rm = TRUE)) %>%
select(YearMonth, ensemble)
return(ensemble)
}
# Example usage:
# Assuming data1_wide is already created using the previous functions
ensemble_result = create_ensembles(data1_wide, models_to_use = c("model1", "model2"))
library(stringr)
library(dplyr)
create_ensembles <- function(data1_wide, models_to_use = "all") {
# Extract models/columns from the data1_wide dataframe
models <- colnames(data1_wide)[-1]  # Assuming the first column is 'YearMonth'
models <- models %>%
str_extract("[a-zA-Z]*_") %>%
str_remove("_") %>%
unique()
if (!identical(models_to_use, "all")) {
missing_models <- setdiff(models_to_use, models)
if (length(missing_models) > 0) {
stop("The following models are not available: ", paste(missing_models, collapse = ", "))
}
models <- models[models %in% models_to_use]
}
# Create ensemble: For the sake of this example, let's assume ensemble means averaging over the selected models.
# Adjust the function as per the real ensemble requirement.
ensemble <- data1_wide %>%
select(c('YearMonth', all_of(models))) %>%
rowwise() %>%
mutate(ensemble = mean(c_across(everything()), na.rm = TRUE)) %>%
select(YearMonth, ensemble)
return(ensemble)
}
head(data1_wide)
create_ensemble_average <- function(data, model_columns) {
# Compute the ensemble average for each row
data$ensemble_avg <- rowMeans(data[, model_columns], na.rm = TRUE)
return(data)
}
# Use the function on the data
model_cols <- colnames(data1_wide)[-(1:4)] # assuming the first 4 columns are not models but meta-data
ensemble_data <- create_ensemble_average(data1_wide, model_cols)
model_cols
create_ensemble_average <- function(data) {
# Compute the ensemble average for all columns
data$ensemble_avg <- rowMeans(data, na.rm = TRUE)
return(data)
}
# Use the function on the data
ensemble_data <- create_ensemble_average(data1_wide)
numeric_cols <- sapply(data1_wide, is.numeric)
data1_wide_numeric <- data1_wide[, numeric_cols]
numeric_cols <- sapply(data1_wide, is.numeric)
data1_wide_numeric <- data1_wide[, numeric_cols]
create_ensemble_average <- function(data) {
# Compute the ensemble average for all columns
data$ensemble_avg <- rowMeans(data, na.rm = TRUE)
return(data)
}
# Use the function on the cleaned data
ensemble_data <- create_ensemble_average(data1_wide_numeric)
ensemble_data
View(ensemble_data)
compute_accuracy_metrics <- function(actual, forecasted) {
# Compute the residuals/errors
residuals <- actual - forecasted
# Compute RMSE
rmse <- sqrt(mean(residuals^2))
# Compute MAPE
mape <- mean(abs(residuals / actual)) * 100
return(list(RMSE = rmse, MAPE = mape))
}
# Assuming you have an ensemble forecast in `ensemble_data$ensemble_avg`
# and the actuals in one of the columns of `data1_wide`. Let's say `data1_wide$actuals`
accuracy <- compute_accuracy_metrics(data1_wide$actuals, ensemble_data$ensemble_avg)
print(accuracy)
str(data1_wide)
View(data1_wide)
library(hts)
reconcile_data1_wide_paths <- function(data1_full) {
# Convert to regular data frame to bypass tsibble constraints
data1_full <- as.data.frame(data1_full)
# Convert YearMonth to date and then filter rows after 2015
data1_wide <- data1_full %>%
unite("key_column", Grouped_Organisation, Grouped_Age, Hospital_ItemName_ENG, sep = "_") %>%
pivot_wider(names_from = key_column, values_from = Number, values_fill = list(Number = 0))
# Convert the data to a gts object
ts_data <- ts(data1_wide[,-1], frequency = 12, start = c(year(min(ymd(paste0(data1_wide$YearMonth, "-01")))), month(min(ymd(paste0(data1_wide$YearMonth, "-01"))))))
gts_obj <- hts(ts_data)
return(gts_obj)
}
# Calling the function
gts_obj = reconcile_data1_wide_paths(data1_full)
gts_obj
numeric_cols <- sapply(data1_wide, is.numeric)
data1_wide_numeric <- data1_wide[, numeric_cols]
create_ensemble_average <- function(data) {
# Compute the ensemble average for all columns
data$ensemble_avg <- rowMeans(data, na.rm = TRUE)
return(data)
}
# Use the function on the cleaned data
ensemble_data <- create_ensemble_average(data1_wide_numeric)
compute_accuracy_metrics <- function(actual, forecasted) {
# Compute the residuals/errors
residuals <- actual - forecasted
# Compute RMSE
rmse <- sqrt(mean(residuals^2))
# Compute MAPE
mape <- mean(abs(residuals / actual)) * 100
return(list(RMSE = rmse, MAPE = mape))
}
# Assuming you have an ensemble forecast in `ensemble_data$ensemble_avg`
# and the actuals in one of the columns of `data1_wide`. Let's say `data1_wide$actuals`
accuracy <- compute_accuracy_metrics(data1_wide$actuals, ensemble_data$ensemble_avg)
print(accuracy)
head(data1_wide)
head(data1_wide, 10)
# Forecast 6 months ahead using ets method
forecasts <- forecast(gts_obj, h = 6, method = "ets")
# First, forecast each individual series with ets
individual_forecasts <- lapply(1:ncol(gts_obj[[1]]), function(i) {
ets_forecast <- forecast(ets(gts_obj[[1]][,i]), h = 6)
return(ets_forecast$mean)
})
# Combine the forecasts into a matrix
forecast_matrix <- do.call(cbind, individual_forecasts)
# Now, reconcile the forecasts using hts
gts_forecast_matrix <- ts(forecast_matrix, frequency = 12)
gts_forecasts <- hts(gts_forecast_matrix)
reconciled_forecasts <- forecast(gts_forecasts, method = "bu")
# Print the reconciled forecasts
print(reconciled_forecasts)
reconciled_forecasts
library(dplyr)
library(tidyr)
library(forecast)
# Group by organisation and sum across all hospitals and age groups
org_data <- data1_wide %>%
select(-Grouped_Age, -Hospital_ItemName_ENG) %>%
group_by(Grouped_Organisation, YearMonth) %>%
summarise(total = sum(Number, na.rm = TRUE)) %>%
ungroup()
forecast_ets <- function(ts_data) {
model <- ets(ts_data)
forecasted <- forecast(model, h = 6)
return(forecasted$mean)
}
# Aggregate by organisation and sum across all hospitals and age groups
org_data <- data1_wide %>%
select(-Grouped_Age, -Hospital_ItemName_ENG) %>%
index_by(Grouped_Organisation, YearMonth) %>%
summarise(total = sum(Number, na.rm = TRUE)) %>%
as.data.frame()  # Convert back to a regular data frame
forecast_ets <- function(ts_data) {
model <- ets(ts_data)
forecasted <- forecast(model, h = 6)
return(forecasted$mean)
}
# Convert the tsibble to a regular data frame
data1_df <- as.data.frame(data1_wide)
# Aggregate data by organisation and sum across all hospitals and age groups
org_data <- data1_df %>%
group_by(Grouped_Organisation, YearMonth) %>%
summarise(total = sum(Number, na.rm = TRUE))
library(hts)
library(forecast)
# Convert your wide data to a hierarchical time series object
g <- hts(data1_wide[, -1:4], characters = c(1, 1, 5))
forecasts <- forecast(gts_forecasts, method = "ets", h = 6)
# Forecast next 6 months
forecast_gts <- forecast(gts_obj, h = 6)
# Assuming gts_obj has been created by your reconcile_data1_wide_paths function
# Number of time series
n_series <- ncol(gts_obj$y)
# Forecast each series independently
independent_forecasts <- lapply(1:n_series, function(i) {
ts_data <- ts(gts_obj$y[,i], frequency = 12)
forecast(auto.arima(ts_data), h = 6)
})
head(gts_obj$y)
head(ts_data)
data1_wide <- reconcile_data1_wide_paths(data1_full)
head(data1_wide)
data1_wide <- reconcile_data1_wide_paths(data1_full)
start_year <- year(min(ymd(paste0(data1_wide$YearMonth, "-01"))))
start_month <- month(min(ymd(paste0(data1_wide$YearMonth, "-01"))))
ts_data_manual <- ts(data1_wide[,-1], frequency = 12, start = c(start_year, start_month))
# Let's try to see the widened version directly
data1_wide_test <- data1_full %>%
unite("key_column", Grouped_Organisation, Grouped_Age, Hospital_ItemName_ENG, sep = "_") %>%
pivot_wider(names_from = key_column, values_from = Number, values_fill = list(Number = 0))
str(data1_wide_test)
data1_full <- data1_grouped_age |>
aggregate_key(Grouped_Organisation/Hospital_ItemName_ENG, Number = sum(Number))
data1_full$key_combined <- paste(data1_full$Grouped_Organisation, data1_full$Hospital_ItemName_ENG, sep = "_")
library(lubridate)
data1_wide <- data1_full %>%
pivot_wider(names_from = key_combined, values_from = Number)
View(data1_full)
library(hts)
reconcile_data1_wide_paths <- function(data1_full) {
# Convert to regular data frame to bypass tsibble constraints
data1_full <- as.data.frame(data1_full)
# Convert YearMonth to date
data1_wide <- data1_full %>%
unite("key_column", Grouped_Organisation, Hospital_ItemName_ENG, sep = "_") %>%
pivot_wider(names_from = key_column, values_from = Number, values_fill = list(Number = 0))
# Convert the data to a gts object
ts_data <- ts(data1_wide[,-1], frequency = 12, start = c(year(min(ymd(paste0(data1_wide$YearMonth, "-01")))), month(min(ymd(paste0(data1_wide$YearMonth, "-01"))))))
gts_obj <- hts(ts_data)
return(gts_obj)
}
# Calling the function
gts_obj = reconcile_data1_wide_paths(data1_full)
# First, forecast each individual series with ets
individual_forecasts <- lapply(1:ncol(gts_obj[[1]]), function(i) {
ets_forecast <- forecast(ets(gts_obj[[1]][,i]), h = 6)
return(ets_forecast$mean)
})
# Combine the forecasts into a matrix
forecast_matrix <- do.call(cbind, individual_forecasts)
# Now, reconcile the forecasts using hts
gts_forecast_matrix <- ts(forecast_matrix, frequency = 12)
gts_forecasts <- hts(gts_forecast_matrix)
reconciled_forecasts <- forecast(gts_forecasts, method = "bu")
# Print the reconciled forecasts
print(reconciled_forecasts)
individual_forecasts <- lapply(1:ncol(gts_obj[[1]]), function(i) {
ets_forecast <- forecast(ets(gts_obj[[1]][,i]), h = 6)
return(ets_forecast$mean)
})
forecast_matrix <- do.call(cbind, individual_forecasts)
gts_forecast_matrix <- ts(forecast_matrix, frequency = 12)
gts_forecasts <- hts(gts_forecast_matrix)
reconciled_forecasts <- forecast(gts_forecasts, method = "bu")
print(reconciled_forecasts)
reconciled_forecasts <- forecast(gts_forecasts, method = "bu", h = 6)
print(reconciled_forecasts)
print(gts_forecasts)
print(gts_forecasts$nodes)
plot(gts_forecasts, levels = 1:2)  # Adjust levels if you have more levels in your hierarchy
str(gts_forecasts)
gts_forecasts$labels$`Level 1` <- paste0("Series_", 1:50)
plot(gts_forecasts, levels = 1:2)
gts_forecast_matrix <- ts(forecast_matrix, frequency = 12)
gts_forecasts <- hts(gts_forecast_matrix, characters = list(1, rep(1, 50)))
# Define hierarchy
hierarchy <- list(Total = paste0("Series_", 1:50))
# Construct the hts object
gts_forecasts <- hts(gts_forecast_matrix, hierarchy = hierarchy)
colnames(gts_forecast_matrix) <- paste0("S", 1:50)
gts_forecasts <- hts(gts_forecast_matrix, characters = c(1, 1))
# If there are 50 columns, name them S01, S02, ..., S50
colnames(gts_forecast_matrix) <- sprintf("S%02d", 1:50)
gts_forecasts <- hts(gts_forecast_matrix, characters = c(1, 2))
plot(gts_forecasts, levels = 1:2)
View(reconciled_forecasts)
data.frame(reconciled_forecasts)
# 1. Extract forecasted values from reconciled_forecasts object
forecasted_values <- matrix(NA, nrow = 6, ncol = 50)  # Assuming you have 50 series and a forecast horizon of 6
for (i in 1:50) {
forecasted_values[, i] <- reconciled_forecasts$forecasts[[i+1]]$mean  # +1 to skip the total level
}
forecasted_values
library(forecast)
# Assuming `reconciled_forecasts` is the forecast object and `data1_test` is the test data
# Extracting the test data for comparison
test_data <- ts(data1_test[, -1], frequency = 12) # Assuming frequency is 12 (monthly data) and the first column is the date
# Decide how many months you want to hold out for testing
h <- 6
# Split the data into training and test set
data1_train <- data1_full %>%
filter(YearMonth < max(YearMonth) - months(h))
# Decide how many months you want to hold out for testing
h <- 6
# Split the data into training and test set
data1_train <- data1_full %>%
filter(as.Date(YearMonth, frac = 1) < max(as.Date(YearMonth, frac = 1)) - months(h))
data1_test <- data1_full %>%
filter(as.Date(YearMonth, frac = 1) >= max(as.Date(YearMonth, frac = 1)) - months(h))
library(forecast)
# Assuming `reconciled_forecasts` is the forecast object and `data1_test` is the test data
# Extracting the test data for comparison
test_data <- ts(data1_test[, -1], frequency = 12) # Assuming frequency is 12 (monthly data) and the first column is the date
# Coerce columns to numeric
data1_test <- data1_test %>%
mutate(across(-1, as.numeric))  # Here, `-1` indicates to convert all columns except the first one.
# Coerce columns to numeric
data1_test_numeric <- data1_test %>%
mutate(across(-1, as.numeric))  # Here, `-1` indicates to convert all columns except the first one.
View(data1_test)
library(forecast)
# Assuming `reconciled_forecasts` is the forecast object and `data1_test` is the test data
# Extracting the test data for comparison
test_data <- ts(data1_test[, -1], frequency = 12) # Assuming frequency is 12 (monthly data) and the first column is the date
# Identify non-numeric columns
non_numeric_cols <- sapply(data1_test, function(col) !is.numeric(col))
# Print the names of these columns
names(data1_test)[non_numeric_cols]
# Assuming you want to keep the date column (first column) and exclude the rest
# Exclude the first column (date) and the non-numeric columns
test_data_cols <- data1_test[, !non_numeric_cols & seq_along(data1_test) != 1]
# Convert the filtered dataset into a time series object
test_data <- ts(test_data_cols, frequency = 12)
# Extracting the mean forecasts (point forecasts) from the reconciled_forecasts object
point_forecasts <- reconciled_forecasts$mean
# Load necessary libraries
library(forecast)
library(tibble)
# Calculate accuracy
accuracy_results <- accuracy(point_forecasts, test_data)
point_forecasts
print(reconciled_forecasts)
forecast_values <- reconciled_forecasts[[1]][[1]]
test_values <- data1_test[1, -c(1:3)] # removing the YearMonth, Grouped_Organisation, and Hospital_ItemName_ENG columns
library(forecast)
accuracy(forecast_values, test_values)
forecast_values <- reconciled_forecasts$allfcasts[[1]]
test_values <- as.numeric(data1_test[1, -c(1:3)]) # converting to numeric
test_values
forecast_values
str(reconciled_forecasts)
base_forecasts <- reconciled_forecasts$bts
historical_data <- reconciled_forecasts$histy
print(base_forecasts)
library(dplyr)
library(lubridate)
# Decide how many months you want to hold out for testing
h <- 6
# Split the data into training and test set
data1_train <- data1_full %>%
filter(as.Date(YearMonth) < max(as.Date(YearMonth)) - months(h))
data1_test <- data1_full %>%
filter(as.Date(YearMonth) >= max(as.Date(YearMonth)) - months(h))
# Extract forecasts
forecasted_values <- reconciled_forecasts$bts
# Convert the test data to a time series matrix similar to the forecasted values
test_data_matrix <- ts(data1_test[, -1], frequency = 12)
# Convert non-numeric columns to numeric
test_data_numeric <- data1_test %>%
select(-YearMonth) %>%
mutate(across(everything(), as.numeric, .names = "numeric_{.col}"))
# Convert data to a matrix excluding non-numeric columns
test_data_matrix <- as.matrix(data1_test[, -c(1, which(names(data1_test) == "Grouped_Organisation"))])
forecasted_values
subset_data <- data1_test[, -c(1, which(names(data1_test) == "Grouped_Organisation"))]
test_data_matrix <- as.matrix(subset_data)
sapply(subset_data, class)
sapply(subset_data, function(col) unique(class(col)))
sapply(subset_data, function(col) unique(class(col)))
subset_df <- as.data.frame(subset_data)
test_data_matrix <- as.matrix(subset_df)
subset_data
view(subset_data)
head(subset_data)
sapply(subset_data, class)
sapply(subset_data, function(col) unique(class(col)))
subset_df <- as.data.frame(subset_data)
test_data_matrix <- as.matrix(subset_df)
test_data_matrix <- matrix(subset_data$Number, nrow = nrow(subset_data))
forecast_values <- matrix(reconciled_forecasts$bts, nrow = nrow(test_data_matrix))
# Ensure that the dimensions of the test data and forecast values match:
if(dim(test_data_matrix)[1] == dim(forecast_values)[1] & dim(test_data_matrix)[2] == dim(forecast_values)[2]){
accuracy_results <- accuracy(forecast_values, test_data_matrix)
print(accuracy_results)
} else {
cat("The dimensions of test data and forecast values do not match. Please check.")
}
if (nrow(test_data_matrix) > nrow(forecast_values)) {
test_data_matrix <- test_data_matrix[1:nrow(forecast_values), ]
}
library(forecast)
# Assuming forecast_values and test_data_matrix are of same dimension now
acc <- accuracy(forecast_values, test_data_matrix)
# 1. Prepare the Test Data:
# Assuming "YearMonth" and "Grouped_Organisation" are non-numeric columns
test_data_matrix <- as.matrix(data1_test %>% select(-YearMonth, -Grouped_Organisation))
sapply(subset_data, class)
sapply(subset_data, function(col) unique(class(col)))
subset_df <- as.data.frame(subset_data)
test_data_matrix <- matrix(subset_data$Number, nrow = nrow(subset_data))
forecast_values <- matrix(reconciled_forecasts$bts, nrow = nrow(test_data_matrix))
# Ensure that the dimensions of the test data and forecast values match:
if(dim(test_data_matrix)[1] == dim(forecast_values)[1] & dim(test_data_matrix)[2] == dim(forecast_values)[2]){
accuracy_results <- accuracy(forecast_values, test_data_matrix)
print(accuracy_results)
} else {
cat("The dimensions of test data and forecast values do not match.")
}
if (nrow(test_data_matrix) > nrow(forecast_values)) {
test_data_matrix <- test_data_matrix[1:nrow(forecast_values), ]
}
# Convert this matrix into a time series object
test_data_ts <- ts(test_data_matrix, frequency = 12)
# 2. Prepare the Forecasted Values:
# I'm assuming `forecast_values` is a matrix with the same number of rows as `test_data_matrix`.
# If not, you might need to adjust this.
forecast_ts <- ts(forecast_values, start=start(test_data_ts), frequency=12)
# 3. Calculate the Accuracy:
acc <- accuracy(forecast_ts, test_data_ts)
print(acc)
# 4. Convert Accuracy Measures to Percentage
accuracy_percentage <- acc %>%
as.data.frame() %>%
mutate_all(~ ifelse(is.na(.), NA, . * 100))  # Convert NAs to NA
print(accuracy_percentage)
