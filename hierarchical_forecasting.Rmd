---
title: "hierarchical_forecasting_report"
author: "Janice Hsu"
date: "2023-09-30"
output:
  bookdown::pdf_document2:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      fig.pos = "H", out.extra = "")
```

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```


\newpage

# Preliminary Analysis

```{r}
# Required Libraries
library(zoo)
library(ggplot2)
library(lubridate)
library(tsibble)
library(tidyverse)
library(fpp3)
library(hts)
library(dplyr)
library(tidyr)
library(forecast)
library(Metrics)
library(purrr)
library(tidyr)
library(stats)
library(fable)
library(dplyr)



```


```{r}
data <- read.csv("HLTH0037_ts_cleaned.csv")
```


## Data Introduction

The dataset contains 10 variables related to the hospitals and information of patients in Wales, UK. Here are the brief summary of the dataset:

- Data: This column represents the number of attendance in each emergency department.

- YearMonth: This column represents dates in the year-month format. Additionally, this dataset contains data from 2012 April to 2023 May.

- Age_Code: This column provides the age group that the patient is in. There are 17 different age groups. They are "0 to 4","5 to 17","18 to 24","25 to 29","30 to 34","35 to 39","40 to 44","45 to 49","50 to 54","55 to 59","60 to 64","65 to 69","70 to 74","75 to 79","80 to 84","85" and "Unknown".

- Sex_ItemName_ENG: This column provides the information of patient's gender. 

- Hospital_Code: This column represents 42 different hospitals in Wales.

- Hospital_ItemName_ENG: This columns refers to the name of the 42 different hospitals in Wales.

- Hospital_Hierarchy: This column represents the code for the health board that the hospital belongs to.

- Hospital_AltCode1: This column provides an alternate code for the hospital.

- Organisation: This column represents the health board.

- Organisation_Code: A code for the organisation as well as the health board.

- There are three hierarchies in this dataset. On the top level, there is all the hospitals in Wales, while on the second hierarchy, there are 6 different health boards which also shown as the organisations. At the bottom level, there are 42 hospitals in total.



\newpage
# Exploratory Data Analysis

```{r}
data <- data %>%
  mutate(YearMonth = yearmonth(YearMonth)) %>%
  as_tsibble(index = YearMonth, key = c(Age_Code, Sex_ItemName_ENG, Hospital_Code, Hospital_ItemName_ENG)) 

```

## Number of patients entering ED under different hospital hierarchy
```{r}

data_hts <- data %>%
  aggregate_key(Organisation/Hospital_ItemName_ENG, Number = sum(Data))
  
data_hts |>
  filter(is_aggregated(Hospital_ItemName_ENG)) |>
  autoplot(Number) +
  labs(y = "Number of patients",
       title = "Number of patients who enter ED") +
  facet_wrap(vars(Organisation), scales = "free_y", ncol = 3) +
  theme(legend.position = "none")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(angle = 0, hjust = 1)) 
```

-	A couple of Local Health Boards (LHBs) were redefined from the 1st of April 2019 onwards: Cwm Taf (27)--> Cwm Taf Morgannwg (30)// Abertawe Bro Morgannwg (26) --> Swansea Bay (31). Therefore, if you decide to forecast at LHB resolution, you might want to consider these 4 as a unique one. 

-	A the Princess of Wales Hospital changed its Local Health Boards

-	So we analyse these 4 as one organisation

\newpage

## Group the changed Local Health Board together

```{r}

data_grouped <- data %>%
  mutate(Aggregated_Organisation = case_when(
    Organisation %in% c("Cwm Taf", "Cwm Taf Morgannwg", "Abertawe Bro Morgannwg", "Swansea Bay") ~ "Grouped_4_organisation",
    TRUE ~ Organisation
  ))

```

### There are 6 Local Health Boards
```{r}
unique(data_grouped$Aggregated_Organisation)
```

```{r}
data2_hts <- data_grouped %>%
  group_by(Aggregated_Organisation) %>%
  summarise(Number = sum(Data))
```

## Number of patients who enter ED under 6 different local health boards
```{r}
data2_hts |>
  ggplot(aes(x = YearMonth, y = Number)) +
  geom_line(stat = "identity") +
  labs(y = "Number of patients",
       title = "Number of patients who enter ED") +
  facet_wrap(vars(Aggregated_Organisation), scales = "free_y", ncol = 3) +
  theme(legend.position = "none") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


Findings: 

- There is a big decline during the Covid-19 period, and after the Covid-19, except the Powys Teaching, other local health boards have increased the number of attendance back to its previous years.

- There seems to be seasonality in the data for each health board, and I would like to investigate more on top of this.

\newpage

## Seasonality of number of attendances

To investigate deeper into the potential seasonality in the data, I would like to decompose the time series according the each health board. It allows us to discover the trend, seasonality and the residual components.



### Decompose Time Series

```{r}

# Decompose time series for each health board using STL
stl_decompositions <- data2_hts %>%
  split(.$Aggregated_Organisation) %>%
  purrr::map(function(data){
    ts_data <- ts(data$Number, frequency = 12)
    stl(ts_data, s.window = "periodic")
  })

# Convert the decompositions to a tidy data frame
stl_df <- purrr::map2_dfr(stl_decompositions, names(stl_decompositions), 
                          ~{
                            time_series <- as.data.frame(.x$time.series)
                            time_series$Aggregated_Organisation <- .y
                            return(time_series)
                          })

```


```{r}
num_months <- length(unique(data2_hts$YearMonth))
num_orgs <- length(unique(data2_hts$Aggregated_Organisation))

# Correct assignment for YearMonth column
stl_df$YearMonth <- rep(unique(data2_hts$YearMonth), times = num_orgs)

```

### Plotting

```{r}
stl_df_tidy <- stl_df %>%
  tidyr::pivot_longer(cols = c(trend, seasonal, remainder), 
                      names_to = "component", 
                      values_to = "value")

```


```{r}
stl_df_tidy %>%
  ggplot(aes(x = YearMonth, y = value, color = component)) +
  geom_line() +
  facet_wrap(vars(Aggregated_Organisation), scales = "free_y", ncol = 3) +
  labs(title = "STL Decomposition of ED Attendance",
       y = "Number of Patients",
       color = "Component") +
  scale_color_manual(values = c("blue", "green", "red"),
                     breaks = c("trend", "seasonal", "remainder"),
                     labels = c("Trend", "Seasonal", "Residual")) +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 45, hjust = 1))

```
Based on the STL decomposition, it is evident that each health board follows a similar trend. Moreover, it is obvious that there is a significant downturn during the Covid-19 era. As for seasonality, there is a pronounced surge in the number of patient's attendance in the middle of the year (approximately in June or July). This seasoanl pattern underlines the recurrent nature of patient admissions.


\newpage

## Change the Age_Code structure into different groups

```{r}
unique(data_grouped$Age_Code)
```


### Age group: "0-4", "5-17", "18-69", "70^"
```{r}
data_grouped_age <- data_grouped %>%
  filter(Age_Code != "Unknown") %>%
  mutate(Grouped_Age = case_when(
    Age_Code == "0 to 4" ~ "0-4",
    Age_Code == "5 to 17" ~ "5-17",
    Age_Code %in% c("18 to 24", "25 to 29", "30 to 34", "35 to 39", 
                    "40 to 44", "45 to 49", "50 to 54", "55 to 59", 
                    "60 to 64", "65 to 69") ~ "18-69",
    Age_Code %in% c("70 to 74", "75 to 79", "80 to 84", "85") ~ "70 and over",
    TRUE ~ "Other"
  ))

```


## Plot Number of Patients in different age groups
```{r}
data_gts <- data_grouped_age %>%
  filter(Sex_ItemName_ENG != "Not Specified or invalid") %>%
  group_by(Grouped_Age, Sex_ItemName_ENG) %>%
  summarize(Number = sum(Data, na.rm = TRUE))

ggplot(data_gts, aes(x = Grouped_Age, y = Number)) +
  geom_bar(stat = "identity") +
  labs(y = "Number of patients") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~ Sex_ItemName_ENG, scales = "free")


```


Findings:

- The observation that the age group 18-69 has the most amount of patient attendance is expected, as it is the biggest group among all. However, it is noteworthy that the second biggest group are from the oldest age bracket, aligning with the general understanding of the health care need for the elders.


```{r}
#Change the data into wide format
data2_wide <- data_grouped %>%
  group_by(Aggregated_Organisation) %>%
  index_by(YearMonth) %>%
  summarise(Number = sum(Data)) %>%
  pivot_wider(names_from = Aggregated_Organisation, values_from = Number)


```

```{r}
data2_wide <- as_tibble(data2_wide)
data2_wide <- data2_wide %>%
   mutate(Total = rowSums(select(., c("Aneurin Bevan", "Betsi Cadwaladr", "Cardiff & Vale", "Grouped_4_organisation", "Hywel Dda", "Powys Teaching")), na.rm = TRUE))

```


# Forecast with ARIMA

### Define the forecast horizon and validation period

```{r}
h <- 12
validation_period <- 6

```


### Splitting the data into training and testing sets
```{r}

training_data <- head(data2_wide, nrow(data2_wide) - validation_period)
test_data <- tail(data2_wide, validation_period)

```


```{r}

cols_to_forecast <- c("Aneurin Bevan", "Betsi Cadwaladr", "Cardiff & Vale", "Grouped_4_organisation", "Hywel Dda", "Powys Teaching", "Total")
forecast_list <- list()

arima_forecast_list <- list()
start_year <- year(min(training_data$YearMonth))
start_month <- month(min(training_data$YearMonth))

for (col in cols_to_forecast) {
  ts_data <- ts(training_data[[col]], start = c(start_year, start_month), frequency = 12)
  arima_model <- auto.arima(ts_data)
  forecast_list[[col]] <- forecast(arima_model, h = h)
}
```

## Plotting using ARIMA

```{r  fig.height=4}

for (col in cols_to_forecast) {
  end_year_train <- year(max(training_data$YearMonth))
  end_month_train <- month(max(training_data$YearMonth))
  
  start_year_test <- ifelse(end_month_train == 12, end_year_train + 1, end_year_train)
  start_month_test <- ifelse(end_month_train == 12, 1, end_month_train + 1)
  
  actual_ts <- ts(test_data[[col]], start = c(start_year_test, start_month_test), frequency = 12)
  
  plot_forecast <- autoplot(forecast_list[[col]]) +
    autolayer(actual_ts, series="Actual", PI=FALSE) +
    labs(title = paste("Forecast vs Actual for", col)) +
    theme(legend.position = "bottom")
  
  print(plot_forecast)
}
```


Due to the impact of Covid-19, the trend of forecast in the future appears to be lower than expected. However, the ARIMA model seems to suggest the consistent direction as the actual data for Cardiff & Vale, Grouped_4_Organisation, Hywel Dda, Powys Teaching and Total (All-Wales). Noticeably, they all have a downturn in the latter half of 2023. 

However, the forecast for Aneurin Bevan and Betsi Cadwaladr are not that accurate according to the divergence between the predicted value and the actual data.

# Forecasting with ETS

```{r}

ets_forecast_list <- list()
start_year <- year(min(training_data$YearMonth))
start_month <- month(min(training_data$YearMonth))

for (col in cols_to_forecast) {
  ts_data <- ts(training_data[[col]], start = c(start_year, start_month), frequency = 12)
  ets_model <- ets(ts_data)  # Use the ets function
  forecast_list[[col]] <- forecast(ets_model, h = h)
}


```

## Plotting with ets
```{r  fig.height=4}
for (col in cols_to_forecast) {
  end_year_train <- year(max(training_data$YearMonth))
  end_month_train <- month(max(training_data$YearMonth))
  
  start_year_test <- ifelse(end_month_train == 12, end_year_train + 1, end_year_train)
  start_month_test <- ifelse(end_month_train == 12, 1, end_month_train + 1)
  
  actual_ts <- ts(test_data[[col]], start = c(start_year_test, start_month_test), frequency = 12)
  
  plot_forecast <- autoplot(forecast_list[[col]]) +
    autolayer(actual_ts, series="Actual", PI=FALSE) +
    labs(title = paste("ETS Forecast vs Actual for", col)) +
    theme(legend.position = "bottom")
  
  print(plot_forecast)
}

```

The prediction from the ETS model aligns closely with the actual data upon the visual inspection. Therefore, It might suggest that a higher accuracy for the ETS model compared to the ARIMA model.

Additionally, all the predictions have a downturn of trend in the latter half of 2023. According to the historial data, this might be due to that the peak appears in the middle of the year followed by a trough at the end and the start of the year.

# Accuracy assessment for ARIMA and ETS

### Lists to store forecasts and error metrics

```{r}
arima_forecast_list <- list()
ets_forecast_list <- list()
arima_error_metrics <- list()
ets_error_metrics <- list()
```

## Forecasting using ARIMA and ETS
```{r}

for (col in cols_to_forecast) {
  ts_data <- ts(training_data[[col]], start = c(start_year, start_month), frequency = 12)
  
  # ARIMA model
  arima_model <- auto.arima(ts_data)
  arima_forecast <- forecast(arima_model, h = h)
  arima_forecast_list[[col]] <- arima_forecast
  
  # ETS model
  tryCatch({
    ets_model <- ets(ts_data)
    ets_forecast <- forecast(ets_model, h = h)
    ets_forecast_list[[col]] <- ets_forecast
  }, error = function(e) {
    cat("Error in forecasting for column:", col, "with message:", e$message, "\n")
  })
}
```

## Calculating Accuracy Metrics for ARIMA and ETS
```{r}

for (col in cols_to_forecast) {
  actual <- test_data[[col]]
  
  arima_forecasted <- head(arima_forecast_list[[col]]$mean, validation_period)
  
  # ARIMA metrics
  arima_MAE <- mae(actual, arima_forecasted)
  arima_RMSE <- rmse(actual, arima_forecasted)
  arima_MAPE <- tryCatch(mape(actual, arima_forecasted), error = function(e) NA)
  arima_error_metrics[[col]] <- list(MAE = arima_MAE, RMSE = arima_RMSE, MAPE = arima_MAPE)
  
  # Check if ETS forecast exists for the column to avoid errors
  if (!is.null(ets_forecast_list[[col]])) {
    ets_forecasted <- head(ets_forecast_list[[col]]$mean, validation_period)
    
    # ETS metrics
    ets_MAE <- mae(actual, ets_forecasted)
    ets_RMSE <- rmse(actual, ets_forecasted)
    ets_MAPE <- tryCatch(mape(actual, ets_forecasted), error = function(e) NA)
    ets_error_metrics[[col]] <- list(MAE = ets_MAE, RMSE = ets_RMSE, MAPE = ets_MAPE)
  }
}

```

### Displaying Accuracy Metrics for each Column
```{r}
for (col in cols_to_forecast) {
  cat("\nAccuracy metrics for:", col, "\n")
  cat("--------------------------\n")
  cat("ARIMA:\n")
  print(arima_error_metrics[[col]])
  cat("ETS:\n")
  print(ets_error_metrics[[col]])
  cat("\n")
  # Add a line break to separate the next set of metrics horizontally
  cat("----------------------------------------------------\n")
}

```


- Most of the error metrics for ETS model are lower than the ARIMA model, except for Cardiff & Vale. 

- The ARIMA model is based on the autoregressive and moving average components of the time series, in line with the differencing method in order to make the data stationary. On the other hand, the ETS model focuses on the error, trend and seasonality components of the time series.

- According to the interest based on the NHS team, they would like to understand what is the best error metric to assess the quality of the forecast for the non-zero count data. Therefore, I would like to provide some insights for the error metrics:


1. **Root Mean Squared Error (RMSE)**
   - **Description**: Measures the square root of the average squared differences between forecast and actual values.
   - **Pros**: It gives more weight to large errors.
   - **Cons**: It can be influenced significantly by outliers. RMSE might be inflated, if the count data is prone to significant spikes or declines, which should not be the problem for this data except for the Covid-19 era.
   
2. **Mean Absolute Percentage Error (MAPE)**
   - **Description**: Measures the average of the absolute percentage errors.
   - **Pros**: It is a relative metric, and is scale-independent and easy to interpret.
   - **Cons**: MAPE can overemphasize relative errors on small counts.
   
3. **Mean Absolute Error (MAE)**
   - **Description**: Measures the average of the absolute differences between forecast and actual values.
   - **Pros**: It's less sensitive to outliers than RMSE. It provides a straightforward average error size.
   - **Cons**: It does not emphasize large errors.



**Recommendation**:

- If you want to penalize larger errors more severely, **RMSE** might be the preferred choice if the larger errors need to be considered, such as the drops in the Covid-19 era.

- For a more balanced view of the average error, **MAE** can be considered.

- **MAPE** is useful and insightful if a relative metric is needed to as it gives error as a percentage of the actual counts.

However, to get a comprehensive overview of the forecast accuracy, it is beneficial to examine on multiple error metrics. Additionally, the choice of the metrics also depend on the specific objectives.



# Reconciliation

## Aggregate data

```{r}
# hierarchy with age group
data_hts <- data_grouped_age |>
  aggregate_key(Aggregated_Organisation / Hospital_ItemName_ENG * Grouped_Age, attendance = sum(Data))
```



```{r}
# hierarchy without age group, only aggregate with the organisation, wales as a big picture
data_wales <- data_grouped_age |>
  aggregate_key(Aggregated_Organisation, attendance = sum(Data))
```




## Time series cross validation


```{r}
library(tscount)
# Split data
training_data <- data_wales %>% 
  filter(YearMonth <= yearmonth("2022 Jun"))

test_data <- data_wales %>% 
  filter(YearMonth > yearmonth("2022 Jun")) 

test_data_filtered <- test_data %>%
  filter(Aggregated_Organisation == "<aggregated>")

```


```{r}
# average the three models
library(fable.tscount)
fit_cv<- training_data %>%
  model(
    naive_model = NAIVE(attendance),
    ets_model = ETS(attendance),
    tscount = TSCOUNT(attendance ~ trend() , link = "log", model = list(past_obs = 1:3))
  )|> mutate (comb = (naive_model+ets_model+tscount)/3)
```




```{r}
# Generate forecasts
fc_cv <- fit_cv %>%
  forecast(h = 12) %>%
  filter(.model == "comb") 

```


```{r}
# Generate forecasts for aggregated
fc_cv_filtered <- fit_cv %>%
  forecast(h = 12) %>%
  filter(.model == "comb") %>%
  filter(Aggregated_Organisation == "<aggregated>")
```


```{r}
# Check the accuracy
forecasted_values <- fc_cv_filtered$.mean

accuracy_value <- accuracy(
  as.data.frame(forecasted_values),as.data.frame(test_data_filtered$attendance))

print(accuracy_value)


```


```{r result_not_expected}

comparison_data <- data.frame(
  Month = yearmonth(test_data$YearMonth),
  Actual = test_data$attendance,
  Forecasted = fc_cv$.mean,
  Aggregated_Organisation = test_data$Aggregated_Organisation  
) 

```


```{r}

comparison_data_long<- comparison_data %>%
  pivot_longer(
    cols = c(Actual, Forecasted),
    names_to = "Type",
    values_to = "Value"
  )



unique_organisations <- unique(comparison_data_long$Aggregated_Organisation)

plot_list <- map(unique_organisations, ~{
  ggplot(comparison_data_long[comparison_data_long$Aggregated_Organisation == .x,], 
         aes(x = Month, y = Value, color = Type)) +
    geom_line() +
    labs(title = paste("Forecasted vs Actual Values for", .x),
         y = "Values") +
    theme_minimal()
})
print(plot_list)


```

```{r}
# Running t-tests and extracting p-value and t-value
t_test_summary <- comparison_data %>%
  group_by(Aggregated_Organisation) %>%
  summarise(
    t_value = list(t.test(Actual, Forecasted)$statistic),
    p_value = list(t.test(Actual, Forecasted)$p.value)
  ) %>%
  unnest(cols = c(t_value, p_value))

print(t_test_summary)

```



```{r}

mape_results <- comparison_data %>%
  group_by(Aggregated_Organisation) %>%
  summarise(
    MAPE = mean(abs((Forecasted - Actual) / Actual), na.rm = TRUE) * 100
  )

print(mape_results)

```






- Base forecasting: applied when forecasting simple time series.
- Reconciliation forecasting (Hierarchical forecasting): it includes forecasting on different levels of aggregation, and it should be applied when dealing with hierarchical or grouped time series.


## Reconcile

### 1. Fitting models and Forecasting


```{r}
forecast_wales <- data_wales |>
  model(ets = ETS(attendance)) |>
  reconcile(bu = bottom_up(ets),
            wls_ETS1 = min_trace(ets, method = "wls_struct"),
            wls_ETS2 = min_trace(ets, method = "wls_var"),
            mint_ETS = min_trace(ets, method = "mint_shrink")) %>%
  forecast(h = 6)
```


```{r}
forecast_wales_avg <- forecast_wales %>%
  as_tibble() %>%
  group_by(Aggregated_Organisation, YearMonth) %>%
  summarise(mean_attendance = mean(.mean, na.rm = TRUE), .groups = "drop")

```

```{r}
forecast_wales_avg$Aggregated_Organisation <- factor(forecast_wales_avg$Aggregated_Organisation)

```

```{r}
ggplot(forecast_wales_avg, aes(x = YearMonth, y = mean_attendance)) +
  geom_line() +
  labs(title = "Average Attendance Forecast",
       x = "Year and Month",
       y = "Average Attendance") +
  facet_wrap(~Aggregated_Organisation, scales = "free_y") +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(angle = 0, hjust = 1))
  
```





```{r}
forecast_wales1 <- data_wales |>
  model(
  tscount = TSCOUNT(attendance ~ trend() , link = "log", model = list(past_obs = 1:3)))|>
  reconcile(bu = bottom_up(tscount),
            wls_ETS1 = min_trace(tscount, method = "wls_struct"),
           wls_ETS2 = min_trace(tscount, method = "wls_var"),
            mint_ETS = min_trace(tscount, method = "mint_shrink")) %>%
  forecast(h = 6)
```

## Include Age Group



```{r}
data_full <- data_grouped_age |>
  aggregate_key((Aggregated_Organisation/Hospital_ItemName_ENG) * Grouped_Age, attendance = sum(Data))

filter_date <- yearmonth("2022 Jun")

fc <- data_full %>%
  filter(yearmonth(YearMonth) <= filter_date) %>%
  model(
    base = ETS(attendance)
  ) %>%
  reconcile(
    bu = bottom_up(base))  %>%
  forecast(h = 18)

```






```{r}
fit <- data_full %>%
  filter(yearmonth(YearMonth) <= filter_date) %>%
  model(
    base = ETS(attendance)
  )

reconciled_fit <- fit %>%
  reconcile(bu = bottom_up(base))

fc_direct <- reconciled_fit %>% forecast(h = 18)

```



```{r}

# Filter the forecast results for aggregated levels and plot
fc %>%
  filter(is_aggregated(Hospital_ItemName_ENG), is_aggregated(Grouped_Age)) %>%
  autoplot(
    data_full %>% filter(yearmonth(YearMonth) >= yearmonth("2020 Jan")),level = NULL
  ) +
  labs(y = "Attendance ('000)") +
  facet_wrap(vars(Aggregated_Organisation), scales = "free_y") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(angle = 0, hjust = 1))

```


```{r}
print(fc)
```


```{r}
setdiff(as.character(unique(data_full$Grouped_Age)), as.character(unique(fc$.model)))
```


```{r}

```



